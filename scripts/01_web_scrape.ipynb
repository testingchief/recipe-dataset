{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# get the html page\n",
    "url_list = [\"https://www.indianhealthyrecipes.com/recipes/south-indian-recipes-food/\",\n",
    "            \"https://www.indianhealthyrecipes.com/recipes/south-indian-recipes-food/page/2/\",\n",
    "            \"https://www.indianhealthyrecipes.com/recipes/south-indian-recipes-food/page/3/\",\n",
    "            \"https://www.indianhealthyrecipes.com/recipes/south-indian-recipes-food/page/4/\",\n",
    "            \"https://www.indianhealthyrecipes.com/recipes/south-indian-recipes-food/page/5/\"\n",
    "            ]\n",
    "custom_headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find required hyperlinks\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "recipe_links = []\n",
    "recipe_data = []\n",
    "\n",
    "for url in url_list:\n",
    "    html_page = requests.get(url, headers=custom_headers)\n",
    "    # print(page.text)\n",
    "\n",
    "    soup = BeautifulSoup(html_page.text, \"html.parser\")\n",
    "    exclusion_list = ['facebook', 'twitter', 'instagram', 'pinterest', 'youtube', 'about', '/receipes/']\n",
    "    for link in soup.findAll('a'):\n",
    "        page_link = link.get('href')\n",
    "        # print(page_link, \" = \", any(ele in link.get('href') for ele in exclusion_list))\n",
    "        try:\n",
    "            if ('indianhealthyrecipes' in str(page_link) and (any(ele in str(page_link)for ele in exclusion_list) is not True)):\n",
    "                #  print(page_link)\n",
    "                recipe_links.append(page_link)\n",
    "        except:\n",
    "            print(\"exception occured \", page_link)\n",
    "# print(recipe_links)\n",
    "print(len(recipe_links))\n",
    "\n",
    "# get unique list\n",
    "recipe_links = list(dict.fromkeys(recipe_links))\n",
    "print(recipe_links)\n",
    "print(len(recipe_links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "limit = 5\n",
    "for index,recipe_url in enumerate(recipe_links):\n",
    "\n",
    "    recipe_data_row = []\n",
    "\n",
    "    # recipe_url = 'https://www.indianhealthyrecipes.com/tomato-rasam-recipe/'\n",
    "    recipe_name = recipe_url.replace('https://www.indianhealthyrecipes.com/', '').replace('/','').replace('-recipe','').replace('recipes','')\n",
    "    print(recipe_name)\n",
    "    \n",
    "    if (recipe_name != ''):\n",
    "        recipe_data_row.append(recipe_name)\n",
    "        recipe_page = requests.get(recipe_url, headers=custom_headers)\n",
    "        recipe_soup = BeautifulSoup(recipe_page.text, \"html.parser\")\n",
    "        ingredients = recipe_soup.find_all('span', attrs = {\"class\": \"wprm-recipe-ingredient-name\"})\n",
    "        ingredients_list = []\n",
    "        for span in ingredients:\n",
    "            ingredients_list.append(span.get_text())\n",
    "\n",
    "        # get unique list\n",
    "        ingredients_list = list(dict.fromkeys(ingredients_list))\n",
    "        recipe_data_row.append(','.join(ingredients_list))\n",
    "\n",
    "        prep_time = recipe_soup.find_all('span', attrs={\"class\": \"wprm-recipe-prep_time-minutes\"})\n",
    "        for span in prep_time:\n",
    "            prep_time_in_mins = span.get_text().replace('minutes', '').replace(' ','')\n",
    "        recipe_data_row.append(prep_time_in_mins)\n",
    "\n",
    "        cook_time = recipe_soup.find_all('span', attrs={\"class\": \"wprm-recipe-cook_time-minutes\"})\n",
    "        for span in cook_time:\n",
    "            cook_time_in_mins = span.get_text().replace('minutes', '').replace(' ','')\n",
    "        recipe_data_row.append(cook_time_in_mins)\n",
    "\n",
    "        recipe_data_row.append(recipe_url)\n",
    "        # print(recipe_data_row)\n",
    "\n",
    "        recipe_data.append(recipe_data_row)\n",
    "        # print(recipe_data)\n",
    "\n",
    "    # if index == limit:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = pd.DataFrame(recipe_data, columns=['recipe','ingredients','prep_time_in_mins','cook_time_in_mins','recipe_link'])\n",
    "# print(df)\n",
    "\n",
    "report_path = os.path.dirname('') + \"../data/recipe-data.csv\"\n",
    "df.to_csv(report_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
